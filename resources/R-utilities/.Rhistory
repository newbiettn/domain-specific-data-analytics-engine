recommmended <- read.csv("recommended_wk.csv", header = FALSE)
################################################################################
dt <- dt %>%
group_by(DATASET, FLOW) %>%
mutate(MEANAUC = mean(WEIGHTEDAREAUNDERROC),
MEANTIMEELAPSED = mean(TIMEELAPSED)) %>%
as.data.frame()
dt <- dt %>%
group_by(DATASET) %>%
arrange(DATASET, desc(MEANAUC)) %>%
mutate(rankByAUC = rank(-MEANAUC, ties.method = "min")) %>%
as.data.frame()
dt <- dt %>%
group_by(DATASET, rankByAUC) %>%
arrange(DATASET, rankByAUC, MEANTIMEELAPSED) %>%
mutate(rankByTime = rank(MEANTIMEELAPSED, ties.method = "random")) %>%
as.data.frame()
myrank <- function(rankByErr, rankByTime){
newrank <- c()
if (length(unique(rankByErr)) == 1){
newrank <- rankByErr + rankByTime - 1
} else {
newrank <- rankByErr
}
return (newrank)
}
dt <- dt %>%
group_by(DATASET, rankByAUC, rankByTime) %>%
arrange(DATASET, rankByAUC, rankByTime) %>%
mutate(rank = myrank(rankByAUC, rankByTime)) %>%
as.data.frame()
################################################################################
ds.names <- unique(as.character(dt$DATASET))
score.list <- list()
k <- 1
for (ds in ds.names){
subset.dt <- dt %>%
filter(DATASET == ds) %>%
as.data.frame()
subset.recommended <- recommmended %>%
filter(V1 == ds) %>%
as.data.frame()
score <- c()
for (j in seq(10, 100, 10)){
list.wk1 <- as.numeric(subset.dt$ID[1:j])
list.wk2 <- as.numeric(subset.recommended[1, 2:(j+1)])
# print(paste0(list.wk1))
# print(paste0(list.wk2))
# print("============================")
names(list.wk1) <- names(list.wk2) <- LETTERS[1:j]
s <- rbo(list.wk1, list.wk2, p = 0.95)
score <- c(score, s)
}
score.list[[k]] <- score
k <- k + 1
}
################################################################################
# Plot
score.list
rm(list = ls(all = T))
################################################################################
library(dplyr)
# library(ggplot2)
library(gespeR)
################################################################################
dt <- read.csv("evaluation_experiment.csv", header = TRUE)
recommmended <- read.csv("recommended_wk.csv", header = FALSE)
################################################################################
dt <- dt %>%
group_by(DATASET, FLOW) %>%
mutate(MEANAUC = mean(WEIGHTEDAREAUNDERROC),
MEANTIMEELAPSED = mean(TIMEELAPSED)) %>%
as.data.frame()
dt <- dt %>%
group_by(DATASET) %>%
arrange(DATASET, desc(MEANAUC)) %>%
mutate(rankByAUC = rank(-MEANAUC, ties.method = "min")) %>%
as.data.frame()
dt <- dt %>%
group_by(DATASET, rankByAUC) %>%
arrange(DATASET, rankByAUC, MEANTIMEELAPSED) %>%
mutate(rankByTime = rank(MEANTIMEELAPSED, ties.method = "random")) %>%
as.data.frame()
myrank <- function(rankByErr, rankByTime){
newrank <- c()
if (length(unique(rankByErr)) == 1){
newrank <- rankByErr + rankByTime - 1
} else {
newrank <- rankByErr
}
return (newrank)
}
dt <- dt %>%
group_by(DATASET, rankByAUC, rankByTime) %>%
arrange(DATASET, rankByAUC, rankByTime) %>%
mutate(rank = myrank(rankByAUC, rankByTime)) %>%
as.data.frame()
################################################################################
ds.names <- unique(as.character(dt$DATASET))
score.list <- list()
k <- 1
for (ds in ds.names){
subset.dt <- dt %>%
filter(DATASET == ds) %>%
as.data.frame()
subset.recommended <- recommmended %>%
filter(V1 == ds) %>%
as.data.frame()
score <- c()
for (j in seq(10, 100, 10)){
list.wk1 <- as.numeric(subset.dt$ID[1:j])
list.wk2 <- as.numeric(subset.recommended[1, 2:(j+1)])
# print(paste0(list.wk1))
# print(paste0(list.wk2))
# print("============================")
names(list.wk1) <- names(list.wk2) <- LETTERS[1:j]
s <- rbo(list.wk1, list.wk2, p = 0.95)
score <- c(score, s)
}
score.list[[k]] <- score
k <- k + 1
}
################################################################################
# Plot
score.list
rm(list = ls(all = T))
################################################################################
library(dplyr)
################################################################################
dt <- read.csv("temp.csv", header = TRUE)
dt$FLOW <- as.factor(dt$FLOW)
n_levels <- length(levels(factor(dt$FLOW)))
# remove workflows that do not perform on all datasets
# for (cluster in 0:max(dt$CLUSTER)){
temp.dt <- dt %>%
# filter(CLUSTER == cluster) %>%
as.data.frame()
num.datasets <- length(unique(temp.dt$DATASET))
tb <- table(temp.dt$CLASSIFIER, temp.dt$ATTRIBUTESELECTION)
rnames <- row.names(tb)
cnames <- colnames(tb)
for (i in 1:nrow(tb)){ #row
for(j in 1:ncol(tb)){ #col
if (tb[i,j] < num.datasets && tb[i,j] > 0){
c <- rnames[i]
a <- cnames[j]
dt <- dt[!(dt$CLASSIFIER == c &
dt$ATTRIBUTESELECTION == a &
dt$CLUSTER == cluster),]
print(paste0(c, "/", a))
}
}
}
# }
rm(list = ls(all = T))
################################################################################
library(dplyr)
################################################################################
dt <- read.csv("temp.csv", header = TRUE)
dt$FLOW <- as.factor(dt$FLOW)
n_levels <- length(levels(factor(dt$FLOW)))
# remove workflows that do not perform on all datasets
# for (cluster in 0:max(dt$CLUSTER)){
temp.dt <- dt %>%
# filter(CLUSTER == cluster) %>%
as.data.frame()
num.datasets <- length(unique(temp.dt$DATASET))
tb <- table(temp.dt$CLASSIFIER, temp.dt$ATTRIBUTESELECTION)
rnames <- row.names(tb)
cnames <- colnames(tb)
for (i in 1:nrow(tb)){ #row
for(j in 1:ncol(tb)){ #col
if (tb[i,j] < num.datasets && tb[i,j] > 0){
c <- rnames[i]
a <- cnames[j]
dt <- dt[!(dt$CLASSIFIER == c &
dt$ATTRIBUTESELECTION == a),]
print(paste0(c, "/", a))
}
}
}
# }
View(dt)
rm(list = ls(all = T))
################################################################################
library(dplyr)
################################################################################
dt <- read.csv("temp.csv", header = TRUE)
dt$FLOW <- as.factor(dt$FLOW)
n_levels <- length(levels(factor(dt$FLOW)))
# remove workflows that do not perform on all datasets
# for (cluster in 0:max(dt$CLUSTER)){
temp.dt <- dt %>%
# filter(CLUSTER == cluster) %>%
as.data.frame()
num.datasets <- length(unique(temp.dt$DATASET))
tb <- table(temp.dt$CLASSIFIER, temp.dt$ATTRIBUTESELECTION)
tb
rnames <- row.names(tb)
cnames <- colnames(tb)
for (i in 1:nrow(tb)){ #row
for(j in 1:ncol(tb)){ #col
if (tb[i,j] < num.datasets && tb[i,j] > 0){
c <- rnames[i]
a <- cnames[j]
dt <- dt[!(dt$CLASSIFIER == c &
dt$ATTRIBUTESELECTION == a),]
print(paste0(c, "/", a))
}
}
}
# }
tb <- table(temp.dt$CLASSIFIER, temp.dt$ATTRIBUTESELECTION)
tb
num.datasets <- length(unique(temp.dt$DATASET))
num.datasets
tb <- table(dt$CLASSIFIER, dt$ATTRIBUTESELECTION)
tb
rm(list = ls(all = T))
################################################################################
library(dplyr)
################################################################################
dt <- read.csv("temp.csv", header = TRUE)
dt$FLOW <- as.factor(dt$FLOW)
n_levels <- length(levels(factor(dt$FLOW)))
# remove workflows that do not perform on all datasets
# for (cluster in 0:max(dt$CLUSTER)){
temp.dt <- dt %>%
# filter(CLUSTER == cluster) %>%
as.data.frame()
num.datasets <- length(unique(temp.dt$DATASET))
tb <- table(temp.dt$CLASSIFIER, temp.dt$ATTRIBUTESELECTION)
tb
rnames <- row.names(tb)
cnames <- colnames(tb)
for (i in 1:nrow(tb)){ #row
for(j in 1:ncol(tb)){ #col
if (tb[i,j] < num.datasets && tb[i,j] > 0){
c <- rnames[i]
a <- cnames[j]
dt <- dt[!(dt$CLASSIFIER == c &
dt$ATTRIBUTESELECTION == a),]
print(paste0(c, "/", a))
}
}
}
# }
dt <- dt %>%
group_by(DATASET) %>%
arrange(DATASET, desc(MEANAUC)) %>%
mutate(rankByAUC = rank(-MEANAUC, ties.method = "min")) %>%
as.data.frame()
dt <- dt %>%
group_by(DATASET, rankByAUC) %>%
arrange(DATASET, rankByAUC, MEANTIMEELAPSED) %>%
mutate(rankByTime = rank(MEANTIMEELAPSED, ties.method = "random")) %>%
as.data.frame()
myrank <- function(rankByErr, rankByTime){
newrank <- c()
if (length(unique(rankByErr)) == 1){
newrank <- rankByErr + rankByTime - 1
} else {
newrank <- rankByErr
}
return (newrank)
}
dt <- dt %>%
group_by(DATASET, rankByAUC, rankByTime) %>%
arrange(DATASET, rankByAUC, rankByTime) %>%
mutate(rank = myrank(rankByAUC, rankByTime)) %>%
as.data.frame()
dt$MEANAUC <- as.numeric(as.character(dt$MEANAUC))
dt$MEANFMEASURE <- as.numeric(as.character(dt$MEANFMEASURE))
dt$MEANPRECISION <- as.numeric(as.character(dt$MEANPRECISION))
dt$MEANRECALL <- as.numeric(as.character(dt$MEANRECALL))
dt$MEANERRORRATE <- as.numeric(as.character(dt$MEANERRORRATE))
dt$MEANTIMEELAPSED <- as.numeric(as.character(dt$MEANTIMEELAPSED))
mask <- apply(dt[c("MEANAUC", "MEANFMEASURE", "MEANPRECISION",
"MEANRECALL", "MEANERRORRATE", "MEANTIMEELAPSED")], 2, is.nan)
dt[is.na(dt)] <- NA
View(dt)
library(readr)
mf_with_dsnames <- read_csv("~/Dropbox/Swinburne/Github/codes/DiabetesDiscoveryV2/resources/R-utilities/mf_with_dsnames.csv",
col_names = FALSE)
View(mf_with_dsnames)
library(readr)
mf_with_dsnames <- read_csv("~/Dropbox/Swinburne/Github/codes/DiabetesDiscoveryV2/resources/R-utilities/mf_with_dsnames.csv")
View(mf_with_dsnames)
library(readr)
mf_with_dsnames <- read_csv("~/Dropbox/Swinburne/Github/codes/DiabetesDiscoveryV2/resources/R-utilities/mf_with_dsnames.csv")
View(mf_with_dsnames)
library(readr)
mf_with_dsnames <- read_csv("~/Dropbox/Swinburne/Github/codes/DiabetesDiscoveryV2/resources/R-utilities/mf_with_dsnames.csv",
col_names = FALSE)
View(mf_with_dsnames)
library(readr)
dataset <- read_csv(NULL)
View(dataset)
library(readr)
dataset <- read_csv(NULL)
View(dataset)
dt <- read.csv("temp.csv", header = TRUE)
View(dt)
View(dt)
library(readr)
dataset <- read_csv(NULL)
View(dataset)
dt <- read.csv("experiment_workflow_ranking_by_dataset.csv", header = TRUE)
View(dt)
dt <- read.csv("mf_with_dsnames.csv", header = TRUE)
View(dt)
dt <- read.csv("mf_with_dsnames.csv", header = FALSE)
View(dt)
rm(list = ls(all = T))
################################################################################
# Load library
################################################################################
list.of.packages <- c("foreach", "mfe", "devtools", "githubinstall", "RWeka",
"foreign", "farff", "missForest", "doParallel", "mice")
# githubinstall::githubinstall("MfeatExtrator")
library(MfeatExtractor)
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# load required packages
load <- lapply(list.of.packages, require, character.only = TRUE)
################################################################################
mainExtraction = function(datafile, option) {
devtools::load_all()
sub.data = gsub(x = list.files(path = "data/datasets/"), pattern = ".arff", replacement = "")
assertChoice(x = datafile, choices = sub.data, .var.name = "datafile")
assertChoice(x = option, choices = c("mfe", "cnet", "comp", "pca", "all", "stat"))
cat(" ---------------------------- \n")
cat(" ** Meta-features extractor ** \n")
cat(" ---------------------------- \n")
cat(paste0(" - Datafile: \t", datafile, "\n"))
cat(paste0(" - Features: \t", option, "\n"))
cat(" ---------------------------- \n")
runExtraction(datafile = datafile, option = option)
cat("\n - Finished!\n")
cat(" ---------------------------- \n")
}
################################################################################
# UCI
files <- list.files("data/datasets/")
files <- sapply(files, function(x) substr(x, 1, nchar(x)-5))
result <- foreach (i = 1:length(files),
.errorhandling = "remove",
.combine = rbind)  %do% {
tryCatch(
expr = {
evalWithTimeout({mainExtraction(files[i], "all")},
timeout = 30)
},
onTimeout = c("error"),
TimeoutException = function(ex) cat("Timeout. Skipping.\n")
)
}
################################################################################
# Join them
source("joinMfeats.R")
joinMfeats()
setwd("~/Dropbox/Swinburne/Github/codes/DiabetesDiscoveryV2/resources/R-utilities")
library(ggplot2)
################################################################################
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
library(grid)
# Make a list from the ... arguments and plotlist
plots <- c(list(...), plotlist)
numPlots = length(plots)
# If layout is NULL, then use 'cols' to determine layout
if (is.null(layout)) {
# Make the panel
# ncol: Number of columns of plots
# nrow: Number of rows needed, calculated from # of cols
layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
ncol = cols, nrow = ceiling(numPlots/cols))
}
if (numPlots==1) {
print(plots[[1]])
} else {
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
# Make each plot, in the correct location
for (i in 1:numPlots) {
# Get the i,j matrix positions of the regions that contain this subplot
matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
layout.pos.col = matchidx$col))
}
}
}
################################################################################
library(ggplot2)
################################################################################
# Get a list of datasets
dt <- read.csv("new_results_backup/mf_uci.csv")
library(ggplot2)
################################################################################
# Get a list of datasets
dt <- read.csv("new_results_backup/mf_uci.csv")
View(dt)
library(ggplot2)
################################################################################
# Get a list of datasets
merged <- read.csv("new_results_backup/mf_uci.csv")
# Number of instances
nb_instances <- merged$valueNumberOfInstances
p1 <- ggplot(merged)+
geom_histogram(aes(x = valueNumberOfInstances), binwidth = 450, color = "black", fill = "white")+
# ggtitle("Number of instances")+
theme(plot.title = element_text(lineheight=.8, face="bold"))+
labs(x = "Number of instances", y = "Number of datasets")+
scale_y_continuous(breaks = seq(0, 300, 100), limits = c(0, 300))+
theme_bw()+
theme(text = element_text(size=25))
p1
library(ggplot2)
################################################################################
# Get a list of datasets
merged <- read.csv("new_results_backup/mf_uci.csv")
# Number of instances
nb_instances <- merged$NumberOfInstances
p1 <- ggplot(merged)+
geom_histogram(aes(x = NumberOfInstances), binwidth = 450, color = "black", fill = "white")+
# ggtitle("Number of instances")+
theme(plot.title = element_text(lineheight=.8, face="bold"))+
labs(x = "Number of instances", y = "Number of datasets")+
scale_y_continuous(breaks = seq(0, 300, 100), limits = c(0, 300))+
theme_bw()+
theme(text = element_text(size=25))
p1
library(ggplot2)
################################################################################
# Get a list of datasets
merged <- read.csv("new_results_backup/mf_uci.csv")
library(ggplot2)
################################################################################
# Get a list of datasets
merged <- read.csv("new_results_backup/mf_uci.csv")
# Number of instances
nb_instances <- merged$NUMBEROFINSTANCES
p1 <- ggplot(merged)+
geom_histogram(aes(x = NUMBEROFINSTANCES), binwidth = 450, color = "black", fill = "white")+
# ggtitle("Number of instances")+
theme(plot.title = element_text(lineheight=.8, face="bold"))+
labs(x = "Number of instances", y = "Number of datasets")+
scale_y_continuous(breaks = seq(0, 300, 100), limits = c(0, 300))+
theme_bw()+
theme(text = element_text(size=25))
p1
library(ggplot2)
################################################################################
# Get a list of datasets
merged <- read.csv("new_results_backup/mf_uci.csv")
# Number of instances
nb_instances <- merged$NUMBEROFINSTANCES
p1 <- ggplot(merged)+
geom_histogram(aes(x = NUMBEROFINSTANCES), binwidth = 450, color = "black", fill = "white")+
# ggtitle("Number of instances")+
theme(plot.title = element_text(lineheight=.8, face="bold"))+
labs(x = "Number of instances", y = "Number of datasets")+
theme_bw()+
theme(text = element_text(size=25))
p1
library(ggplot2)
################################################################################
# Get a list of datasets
dt <- read.csv("new_results_backup/mf_uci.csv")
dt <- dt[c("NUMBEROFCLASSES", "NUMBEROFFEATURES", "NUMBEROFINSTANCES")]
View(dt)
library(ggplot2)
library(xtable)
################################################################################
# Get a list of datasets
dt <- read.csv("new_results_backup/mf_uci.csv")
dt <- dt[c("DATASET", "NUMBEROFCLASSES", "NUMBEROFFEATURES", "NUMBEROFINSTANCES")]
xtable(dt)
?sort
sort(dt$DATASET)
library(dplyr)
library(ggplot2)
library(xtable)
################################################################################
# Get a list of datasets
dt <- read.csv("new_results_backup/mf_uci.csv")
dt <- dt[c("DATASET", "NUMBEROFCLASSES", "NUMBEROFFEATURES", "NUMBEROFINSTANCES")]
dt <- dt %>%
arrange(DATASET) %>%
as.data.frame()
View(dt)
library(dplyr)
library(ggplot2)
library(xtable)
################################################################################
# Get a list of datasets
dt <- read.csv("new_results_backup/mf_uci.csv")
dt <- dt[c("DATASET", "NUMBEROFCLASSES", "NUMBEROFFEATURES", "NUMBEROFINSTANCES")]
dt <- dt %>%
arrange(DATASET) %>%
as.data.frame()
xtable(dt)
